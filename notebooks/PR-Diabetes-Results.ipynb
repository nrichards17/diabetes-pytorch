{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diabetes Dataset Process and Results\n",
    "Nathaniel Richards - 10/23/18\n",
    "\n",
    "From UCI ML Repository    \n",
    "[\"Diabetes 130-US hospitals for years 1999-2008 Data Set\"](https://archive.ics.uci.edu/ml/datasets/diabetes+130-us+hospitals+for+years+1999-2008#)\n",
    "\n",
    "**Goal**: build model(s) to predict which patients will be re-hospitalized within 30 days\n",
    "\n",
    "**Evaluate**: using AUROC\n",
    "\n",
    "Notes:\n",
    "- 'encounter_id' - unique admissions\n",
    "- ignore 'patient_nbr' - treat all encounters independent\n",
    "- 'readmitted' - treat 'NO' as '>30'\n",
    "- Attributes: 55\n",
    "- Samples: >100k\n",
    "- Features: numerical, categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Approach\n",
    "\n",
    "1. Exploration\n",
    "    1. feature names\n",
    "    1. feature types\n",
    "    1. missing values\n",
    "    1. numerical histograms\n",
    "    1. categorical value counts\n",
    "1. Preprocessing\n",
    "    1. drop rows\n",
    "        - missing data\n",
    "        - other insights from exploration\n",
    "    1. recode categorical features\n",
    "        - reduce dimensionality\n",
    "    1. convert types\n",
    "        - numerical to categorical\n",
    "        - categorical to numerical\n",
    "    1. determine feature subset\n",
    "    1. upsampling / downsampling\n",
    "    1. train / validation / test split\n",
    "1. Modeling\n",
    "    1. Baseline models\n",
    "        - logistic regression\n",
    "        - SVC\n",
    "    1. Advanced models\n",
    "        - DNN w/ categorical embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Considerations\n",
    "\n",
    "1. Imbalanced classes\n",
    "    - <30 only accounts for 11% of data\n",
    "1. Upsampling / downsampling\n",
    "    - Must be careful if upsampling, risk of information leakage between train/test\n",
    "1. Train / val / test split\n",
    "    - Ensure no information leakage, otherwise overly optimistic results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Literature Survey\n",
    "\n",
    "After planning out how I would approach this problem, I did some research on how others have performed on this open-source dataset.  Listed below are some articles that I found, including my inspiration and comments.\n",
    "\n",
    "### [How to use machine learning to predict hospital readmissions?](https://medium.com/@uraza/how-to-use-machine-learning-to-predict-hospital-readmissions-part-1-bd137cbdba07)   \n",
    "by Usman Raza\n",
    "\n",
    "Reported test accuracy: 94%\n",
    "\n",
    "Notes\n",
    "- remove weight, payer_code, medical_specialty\n",
    "- recode diagnoses {1,2,3}\n",
    "- group similar admission/discharge categories\n",
    "- convert age ranges to numerical mean\n",
    "- drop subjects' second, third, etc visits\n",
    "\n",
    "Pros\n",
    "- extremely thorough set of blog posts\n",
    "- insightful feature engineering/reduction\n",
    "- references the paper associated with dataset\n",
    "- uses pandas\n",
    "- strong statistical background\n",
    "\n",
    "Cons\n",
    "- **overinflated train/test performance**\n",
    "\n",
    "Why? Because of the way he performed upsampling.  He performed SMOTE upsampling *before* the train/test split, causing much of the training data information to end up in the test set.  This is how he was able to achieve such a high accuracy/AUROC compared to other literature.\n",
    "\n",
    "\n",
    "### [STATS701 Project](https://jrfarrer.github.io/stat701_miniproject/)\n",
    "by Jordan Farrer\n",
    "\n",
    "Reported AUROC: <0.64\n",
    "\n",
    "Notes\n",
    "- confirms that modeling is difficult/impossible with such unbalanced classes\n",
    "\n",
    "Pros\n",
    "- great visualization, exploration\n",
    "\n",
    "Cons\n",
    "- did not perform upsampling/downsampling, left classes unbalanced\n",
    "- poor model performance as a result\n",
    "- similar performance to naive model (only predicting one class)\n",
    "- unbalanced confusion matrix\n",
    "\n",
    "\n",
    "### [Predicting Hospital Readmission for Patients with Diabetes Using Scikit-Learn](https://towardsdatascience.com/predicting-hospital-readmission-for-patients-with-diabetes-using-scikit-learn-a2e359b15f0)\n",
    "by Andrew Long\n",
    "\n",
    "Reported AUROC: ~0.65\n",
    "\n",
    "Notes\n",
    "- recode medical_specialty categories\n",
    "- most weight values missing, but adds feature 'has_weight' as presence of weight record\n",
    "- many models evaluated\n",
    "- reports AUC\n",
    "- performs hyperparameter optimization\n",
    "\n",
    "Pros\n",
    "- follows clear data science process\n",
    "- train / val / test split\n",
    "- properly performs subsampling after train/val split\n",
    "- performs continuous feature scaling\n",
    "\n",
    "Cons\n",
    "- one-hot encoding? - may not be negative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Resources\n",
    "\n",
    "### [The Right Way to Oversample in Predictive Modeling](https://beckernick.github.io/oversampling-modeling/)\n",
    "by Nick Becker\n",
    "\n",
    "This article details the subtle-yet-dangerous pitfall of performing upsampling incorrectly.  One should apply SMOTE upsampling *after* the train/test split, otherwise information will leak between the train/test sets, resulting in inflated performance - the model has already trained on the data in the test set.\n",
    "\n",
    "### [Building A Logistic Regression in Python, Step by Step](https://towardsdatascience.com/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8)\n",
    "by Susan Li\n",
    "\n",
    "- Converts categorical features to one-hot\n",
    "- Performs SMOTE on one-hot\n",
    "- Properly performs SMOTE on train set after train/test split\n",
    "- Recursive feature elimination (RFE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expectations\n",
    "\n",
    "I first came upon the results from [Usman Raza](https://medium.com/@uraza/how-to-use-machine-learning-to-predict-hospital-readmissions-part-1-bd137cbdba07) that reported 94% test accuracy on the Diabetes dataset.\n",
    "\n",
    "However, these results were inflated (see above), and other results show an average test performance around AUC=0.65 .  In my model evaluation, this is my target to meet or exceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
